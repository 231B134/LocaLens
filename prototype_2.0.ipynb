{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4a61ba-04cc-4dcf-ac16-316b7d3b6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "import json # <-- ADDED for saving scan times\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox, HBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a10ca25-6b17-460b-92e8-1497b3c4e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Directory: D:\\project\\Localens_experiment\n",
      "Dataset Directory: D:\\project\\Localens_experiment\\dataset\n",
      "Database File: D:\\project\\Localens_experiment\\image_data.csv\n",
      "Timestamps File: D:\\project\\Localens_experiment\\last_scan_times.json\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# CELL 2: PATHS & CONFIGURATION\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "BASE_DIR = r\"D:\\project\\Localens_experiment\"\n",
    "DATASET_DIR = os.path.join(BASE_DIR, \"dataset\")\n",
    "\n",
    "# 1. Your database file\n",
    "CSV_PATH = os.path.join(BASE_DIR, \"image_data.csv\")\n",
    "\n",
    "# 2. NEW: File to store the dictionary of last scan times per folder\n",
    "TIMESTAMPS_FILE = os.path.join(BASE_DIR, \"last_scan_times.json\")\n",
    "\n",
    "# 3. Define the database columns --- (THIS IS THE MODIFIED LINE) ---\n",
    "DB_COLUMNS = ['path', 'folder', 'timestamp', 'R', 'G', 'B', 'objects']\n",
    "\n",
    "print(f\"Base Directory: {BASE_DIR}\")\n",
    "print(f\"Dataset Directory: {DATASET_DIR}\")\n",
    "print(f\"Database File: {CSV_PATH}\")\n",
    "print(f\"Timestamps File: {TIMESTAMPS_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd27b42e-63fc-4b9f-b20b-45f9ee1e7eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database and helper functions are ready.\n"
     ]
    }
   ],
   "source": [
    "def initialize_database():\n",
    "    \"\"\"\n",
    "    Creates the CSV and JSON files with headers if they don't exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(CSV_PATH):\n",
    "        print(f\"Creating new database file: {CSV_PATH}\")\n",
    "        # Create an empty DataFrame with just the columns\n",
    "        df = pd.DataFrame(columns=DB_COLUMNS)\n",
    "        df.to_csv(CSV_PATH, index=False)\n",
    "    \n",
    "    if not os.path.exists(TIMESTAMPS_FILE):\n",
    "        print(f\"Creating new timestamps file: {TIMESTAMPS_FILE}\")\n",
    "        # Create an empty JSON file\n",
    "        with open(TIMESTAMPS_FILE, 'w') as f:\n",
    "            json.dump({}, f)\n",
    "\n",
    "def load_database():\n",
    "    \"\"\"Loads the database CSV.\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(CSV_PATH)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        # File is empty, return a blank DataFrame with correct columns\n",
    "        return pd.DataFrame(columns=DB_COLUMNS)\n",
    "\n",
    "def save_database(df):\n",
    "    \"\"\"Saves the DataFrame back to the database CSV.\"\"\"\n",
    "    df.to_csv(CSV_PATH, index=False)\n",
    "\n",
    "def load_scan_times():\n",
    "    \"\"\"Loads the per-folder timestamp dictionary from the JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(TIMESTAMPS_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        # File is corrupt or empty, return empty dict\n",
    "        return {}\n",
    "\n",
    "def save_scan_times(times_dict):\n",
    "    \"\"\"Saves the timestamp dictionary back to the JSON file.\"\"\"\n",
    "    with open(TIMESTAMPS_FILE, 'w') as f:\n",
    "        json.dump(times_dict, f, indent=2)\n",
    "\n",
    "# --- Run the initialization ---\n",
    "initialize_database()\n",
    "print(\"Database and helper functions are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca27765a-be55-4a11-bd80-c0ab68c75437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image processing functions defined.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# CELL 4: COLOR LOGIC & IMAGE PROCESSING\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def classify_color(h, s, v):\n",
    "    # (Your original function, unchanged)\n",
    "    h = int(h)\n",
    "    s = int(s)\n",
    "    v = int(v)\n",
    "    h_deg = h * 2 \n",
    "\n",
    "    if v < 40 and s < 60:\n",
    "        return \"black\"\n",
    "    if v > 230 and s < 30:\n",
    "        return \"white\"\n",
    "    if v > 180 and s < 40:\n",
    "        return \"gray\"\n",
    "    if 15 <= h_deg <= 35:\n",
    "        if v < 120:\n",
    "            return \"brown\"   \n",
    "        elif 120 <= v <= 200:\n",
    "            return \"orange\" \n",
    "        else:\n",
    "            return \"yellow\"  \n",
    "    if 35 < h_deg <= 85:\n",
    "        return \"green\"\n",
    "    if 85 < h_deg <= 150:\n",
    "        return \"cyan\"\n",
    "    if 150 < h_deg <= 260:\n",
    "        return \"blue\"\n",
    "    if 260 < h_deg <= 320:\n",
    "        return \"purple\"\n",
    "    if 320 < h_deg <= 345:\n",
    "        return \"pink\"\n",
    "    if h_deg < 15 or h_deg > 345:\n",
    "        return \"red\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def extract_dominant_color_lab(image, k=5):\n",
    "    # (Your original function, unchanged)\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    pixels = lab.reshape(-1, 3)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10)\n",
    "    kmeans.fit(pixels)\n",
    "\n",
    "    unique, counts = np.unique(kmeans.labels_, return_counts=True)\n",
    "    dominant_cluster = unique[np.argmax(counts)]\n",
    "    dominant_color = kmeans.cluster_centers_[dominant_cluster]\n",
    "\n",
    "    lab_color = np.uint8([[dominant_color]])\n",
    "    bgr_color = cv2.cvtColor(lab_color, cv2.COLOR_LAB2BGR)\n",
    "    hsv_color = cv2.cvtColor(bgr_color, cv2.COLOR_BGR2HSV)[0][0]\n",
    "\n",
    "    h, s, v = hsv_color\n",
    "    label = classify_color(h, s, v)\n",
    "\n",
    "    return h, s, v, label\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"\n",
    "    MODIFIED: Returns dict matching new columns.\n",
    "    - Removes H, S, V.\n",
    "    - Adds 'objects' column as None.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    \n",
    "    # We still need h, s, v to calculate RGB\n",
    "    h, s, v, label = extract_dominant_color_lab(img)\n",
    "    rgb = cv2.cvtColor(np.uint8([[[h, s, v]]]), cv2.COLOR_HSV2RGB)[0][0]\n",
    "    \n",
    "    file_mod_time = os.path.getmtime(image_path)\n",
    "\n",
    "    # --- THIS IS THE MODIFIED RETURN VALUE ---\n",
    "    return {\n",
    "        \"path\": os.path.normpath(image_path),\n",
    "        \"folder\": os.path.normpath(os.path.dirname(image_path)),\n",
    "        \"timestamp\": file_mod_time,\n",
    "        \"R\": int(rgb[0]), \"G\": int(rgb[1]), \"B\": int(rgb[2]),\n",
    "        \"objects\": None # Set to None (will be 'NaN' in CSV)\n",
    "    }\n",
    "\n",
    "print(\"Image processing functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6811a333-571b-4d4a-a015-1e1a1452fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running automatic scan for new images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning dataset: 0it [00:00, ?it/s]\n",
      "Scanning extra: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<?, ?it/s]\n",
      "Scanning new_images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:00<00:00, 32124.28it/s]\n",
      "Scanning unlabeled: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scan complete. No new images found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def scan_for_new_images():\n",
    "    \"\"\"\n",
    "    Scans DATASET_DIR, compares against last scan times,\n",
    "    and appends only new images to the database.\n",
    "    \"\"\"\n",
    "    print(\"Running automatic scan for new images...\")\n",
    "    \n",
    "    # 1. Load current state\n",
    "    df = load_database()\n",
    "    scan_times = load_scan_times()\n",
    "    \n",
    "    # Use a Set for very fast lookup of paths we already have\n",
    "    paths_in_db = set(df['path'])\n",
    "    new_records = []\n",
    "    \n",
    "    # This will hold the newest timestamp we find in each folder\n",
    "    new_max_times = scan_times.copy()\n",
    "\n",
    "    # 2. Walk through all folders and files\n",
    "    # We use os.walk as it's the most efficient way\n",
    "    for dirpath, dirnames, filenames in os.walk(DATASET_DIR):\n",
    "        \n",
    "        current_folder = os.path.normpath(dirpath)\n",
    "        \n",
    "        # Get the last scan time for this folder, default to 0 if folder is new\n",
    "        last_scan = scan_times.get(current_folder, 0)\n",
    "        \n",
    "        current_max_time_in_folder = last_scan\n",
    "\n",
    "        # Use tqdm for a progress bar on the files in this folder\n",
    "        for fname in tqdm(filenames, desc=f\"Scanning {os.path.basename(current_folder)}\"):\n",
    "            filepath = os.path.normpath(os.path.join(current_folder, fname))\n",
    "\n",
    "            # --- CHECK 1: Is it already in our DB? ---\n",
    "            if filepath in paths_in_db:\n",
    "                continue\n",
    "\n",
    "            # --- CHECK 2: Is the file new? ---\n",
    "            try:\n",
    "                file_time = os.path.getmtime(filepath)\n",
    "            except FileNotFoundError:\n",
    "                continue # File might have been deleted as we were scanning\n",
    "\n",
    "            if file_time > last_scan:\n",
    "                # This is a new file!\n",
    "                # print(f\"  [NEW] Found: {fname}\") # Uncomment for more detail\n",
    "                \n",
    "                # Process it\n",
    "                result = process_image(filepath)\n",
    "                if result:\n",
    "                    new_records.append(result)\n",
    "            \n",
    "            # Update the newest time we've seen in this folder\n",
    "            if file_time > current_max_time_in_folder:\n",
    "                current_max_time_in_folder = file_time\n",
    "\n",
    "        # 3. Update the max scan time for this folder if it changed\n",
    "        if current_max_time_in_folder > last_scan:\n",
    "            new_max_times[current_folder] = current_max_time_in_folder\n",
    "\n",
    "    # 4. Save all new data\n",
    "    if new_records:\n",
    "        print(f\"\\nFound {len(new_records)} new images. Appending to database...\")\n",
    "        new_df = pd.DataFrame(new_records, columns=DB_COLUMNS)\n",
    "        \n",
    "        # Use pd.concat to append new rows\n",
    "        df_updated = pd.concat([df, new_df], ignore_index=True)\n",
    "        \n",
    "        save_database(df_updated)\n",
    "        save_scan_times(new_max_times)\n",
    "        print(\"Database updated.\")\n",
    "    else:\n",
    "        print(\"\\nScan complete. No new images found.\")\n",
    "        # We still save scan times, in case new empty folders were found\n",
    "        save_scan_times(new_max_times)\n",
    "\n",
    "# --- Run the automatic scan ---\n",
    "scan_for_new_images()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95c07c9d-6451-4ab2-929b-f9a5566e1947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MANUAL scan for deleted images...\n",
      "Checking 321 image records...\n",
      "No deleted images found in CSV.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Checking for deleted folders in timestamps file...\n",
      "No deleted folders found in timestamps JSON.\n",
      "\n",
      "Manual scan complete.\n",
      "\n",
      "Manual delete scan function is ready.\n",
      "To run it again, type 'scan_for_deleted_images()' in a new cell and run it.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# CELL 6: CORE - MANUAL \"DELETED IMAGE\" SCAN (UPGRADED V2)\n",
    "# ----------------------------------------------------------------------\n",
    "# (This version cleans both files but does NOT print every\n",
    "# deleted image path, only a summary.)\n",
    "\n",
    "def scan_for_deleted_images():\n",
    "    \"\"\"\n",
    "    Loads the database, checks if every file path still exists,\n",
    "    and removes records for deleted files.\n",
    "    \n",
    "    UPGRADED: This function also checks for deleted folders in the\n",
    "    timestamps JSON and cleans it.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. CLEAN THE IMAGE CSV (image_data.csv) ---\n",
    "    print(\"Running MANUAL scan for deleted images...\")\n",
    "    \n",
    "    df = load_database()\n",
    "    if df.empty:\n",
    "        print(\"Database is empty. Nothing to clean.\")\n",
    "    else:\n",
    "        initial_count = len(df)\n",
    "        print(f\"Checking {initial_count} image records...\")\n",
    "\n",
    "        exists_mask = df['path'].apply(os.path.exists)\n",
    "        df_clean = df[exists_mask]\n",
    "        df_deleted = df[~exists_mask]\n",
    "\n",
    "        deleted_count = len(df_deleted)\n",
    "        if deleted_count > 0:\n",
    "            # --- MODIFICATION ---\n",
    "            # We no longer print every single file.\n",
    "            print(f\"Found {deleted_count} deleted images. Removing from CSV.\")\n",
    "            \n",
    "            save_database(df_clean)\n",
    "            print(f\"Removed {deleted_count} records. {len(df_clean)} records remain in CSV.\")\n",
    "        else:\n",
    "            print(\"No deleted images found in CSV.\")\n",
    "\n",
    "    print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "\n",
    "    # --- 2. CLEAN THE FOLDER JSON (last_scan_times.json) ---\n",
    "    print(\"Checking for deleted folders in timestamps file...\")\n",
    "    scan_times = load_scan_times()\n",
    "    \n",
    "    if not scan_times:\n",
    "        print(\"Timestamps file is empty. Nothing to clean.\")\n",
    "        return\n",
    "\n",
    "    # We will build a new, clean dictionary\n",
    "    clean_scan_times = {}\n",
    "    deleted_folder_count = 0\n",
    "    \n",
    "    for folder_path, timestamp in scan_times.items():\n",
    "        if os.path.exists(folder_path):\n",
    "            # Folder still exists, keep it\n",
    "            clean_scan_times[folder_path] = timestamp\n",
    "        else:\n",
    "            # Folder is deleted, drop it\n",
    "            #print(f\"  - Deleted folder found: {folder_path}\")\n",
    "            deleted_folder_count += 1\n",
    "            \n",
    "    if deleted_folder_count > 0:\n",
    "        save_scan_times(clean_scan_times)\n",
    "        print(f\"Removed {deleted_folder_count} deleted folders from timestamps JSON.\")\n",
    "    else:\n",
    "        print(\"No deleted folders found in timestamps JSON.\")\n",
    "\n",
    "    print(\"\\nManual scan complete.\")\n",
    "\n",
    "# --- To run this, uncomment the line below in this cell ---\n",
    "# scan_for_deleted_images()\n",
    "\n",
    "# --- Or, just run it immediately this time ---\n",
    "scan_for_deleted_images()\n",
    "\n",
    "print(\"\\nManual delete scan function is ready.\")\n",
    "print(\"To run it again, type 'scan_for_deleted_images()' in a new cell and run it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f667a7-2dec-493e-a852-8922b94559a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MANUAL scan for deleted images...\n",
      "Checking 321 image records...\n",
      "No deleted images found in CSV.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Checking for deleted folders in timestamps file...\n",
      "No deleted folders found in timestamps JSON.\n",
      "\n",
      "Manual scan complete.\n"
     ]
    }
   ],
   "source": [
    "scan_for_deleted_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e59ca309-359e-41e8-9ad1-1016fe442b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading database for search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97879de1ecc48cd97e595b6ef2861e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(ColorPicker(value='white', description='Pick a color', style=DescriptionStyle(deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# CELL 7: NEW - INTERACTIVE SEARCH WIDGETS\n",
    "# ----------------------------------------------------------------------\n",
    "# (This REPLACES your old text-based search cell)\n",
    "\n",
    "# --- 1. Load the database ---\n",
    "print(\"Loading database for search...\")\n",
    "df = load_database()\n",
    "if df.empty:\n",
    "    print(\"WARNING: Database is empty. Please run Cell 5 to scan for images.\"\n",
    "         )\n",
    "\n",
    "# --- 2. Helper function to convert color format ---\n",
    "def hex_to_rgb(hex_code):\n",
    "    \"\"\"Converts a hex color string (e.g., #FF0000) to an (R, G, B) tuple.\"\"\"\n",
    "    hex_code = hex_code.lstrip('#')\n",
    "    return tuple(int(hex_code[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "# --- 3. Create the UI Widgets ---\n",
    "color_picker = widgets.ColorPicker(\n",
    "    concise=False,\n",
    "    description='Pick a color',\n",
    "    value='white',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "radius_slider = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=10,\n",
    "    max=255, # Max possible distance in one channel\n",
    "    step=5,\n",
    "    description='Search Radius:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "search_button = widgets.Button(\n",
    "    description='Search',\n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "# This is where all results will be printed\n",
    "results_output = widgets.Output()\n",
    "\n",
    "# --- 4. Define the Search Function (what happens on click) ---\n",
    "def on_search_button_clicked(b):\n",
    "    \"\"\"\n",
    "    This function runs when the search button is clicked.\n",
    "    It performs the radius search and displays results.\n",
    "    \"\"\"\n",
    "    # 1. Clear any old results\n",
    "    results_output.clear_output(wait=True)\n",
    "    \n",
    "    with results_output:\n",
    "        if df.empty:\n",
    "            print(\"Database is empty. Nothing to search.\")\n",
    "            return\n",
    "\n",
    "        # 2. Get values from the widgets\n",
    "        hex_color = color_picker.value\n",
    "        radius = radius_slider.value\n",
    "        target_rgb = np.array(hex_to_rgb(hex_color))\n",
    "\n",
    "        print(f\"Searching for color {target_rgb} within a radius of {radius}...\")\n",
    "        \n",
    "        # 3. Calculate distance for ALL images at once (very fast)\n",
    "        # Get all RGB values from the DataFrame\n",
    "        db_rgbs = df[['R', 'G', 'B']].values \n",
    "        \n",
    "        # Calculate Euclidean distance\n",
    "        # np.sum((db_rgbs - target_rgb)**2, axis=1) -> calculates (r1-r2)^2 + (g1-g2)^2 + (b1-b2)^2\n",
    "        # np.sqrt(...) -> takes the square root\n",
    "        distances = np.sqrt(np.sum((db_rgbs - target_rgb) ** 2, axis=1))\n",
    "        \n",
    "        # 4. Filter the DataFrame\n",
    "        # Select all rows where the distance is within our radius\n",
    "        results_df = df[distances <= radius].copy()\n",
    "        \n",
    "        if results_df.empty:\n",
    "            print(\"No matches found.\")\n",
    "            return\n",
    "            \n",
    "        # 5. Sort and Display\n",
    "        # We can add the 'dist' column for sorting\n",
    "        results_df['dist'] = distances[distances <= radius]\n",
    "        results_df_sorted = results_df.sort_values(['dist', 'timestamp'], ascending=[True, False])\n",
    "\n",
    "        print(f\"Found {len(results_df_sorted)} matches:\")\n",
    "        \n",
    "        for _, row in results_df_sorted.iterrows():\n",
    "            date_str = datetime.fromtimestamp(row['timestamp']).strftime('%Y-%m-%d')\n",
    "            print(f\"\\nðŸ–¼ï¸ {row['path']} | Dist: {row['dist']:.0f} | Date: {date_str}\")\n",
    "            \n",
    "            if os.path.exists(row[\"path\"]):\n",
    "                display(Image(filename=row[\"path\"], width=200))\n",
    "            else:\n",
    "                print(f\"   (Image file missing: {row['path']})\")\n",
    "\n",
    "# --- 5. Link the button to the function ---\n",
    "search_button.on_click(on_search_button_clicked)\n",
    "\n",
    "# --- 6. Display the UI ---\n",
    "# HBox places widgets horizontally\n",
    "input_controls = HBox([color_picker, radius_slider, search_button])\n",
    "# VBox places them vertically\n",
    "display(VBox([input_controls, results_output]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd48ca0-4a12-4f13-989a-c6d2359542cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
